From a184448479b37b3c1f62b7d841c1bf8bd49ed855 Mon Sep 17 00:00:00 2001
From: Zhang Heng <zhangheng@mprc.pku.edu.cn>
Date: Fri, 18 May 2018 00:37:38 +0800
Subject: [PATCH 24/26] adjust VM Entry and VM exit

Signed-off-by: Zhang Heng <zhangheng@mprc.pku.edu.cn>

1.previous privilege for VM saved at hstatus, instead of sstatus.
2.disable interrrupt before VM Entry and after VM Exit
3.get VM Exit reason from hcause
---
 arch/riscv/include/asm/kvm_host.h |  4 +--
 arch/riscv/kvm/kvm_riscv.c        | 61 ++++++++++++++++++++++++++-------------
 2 files changed, 43 insertions(+), 22 deletions(-)

diff --git a/arch/riscv/include/asm/kvm_host.h b/arch/riscv/include/asm/kvm_host.h
index 6227609..ad9dc46 100644
--- a/arch/riscv/include/asm/kvm_host.h
+++ b/arch/riscv/include/asm/kvm_host.h
@@ -181,7 +181,7 @@ void kvm_arch_vcpu_blocking(struct kvm_vcpu *vcpu);
 void kvm_arch_vcpu_unblocking(struct kvm_vcpu *vcpu);
 void kvm_arch_vcpu_block_finish(struct kvm_vcpu *vcpu);
 
-int handle_vm_exit(struct kvm_vcpu *vcpu);
+int handle_vm_exit(struct kvm_vcpu *vcpu, unsigned long cause, unsigned long gpa);
 int handle_h_ecall(struct kvm_vcpu *vcpu);
-int handle_host_page_fault(struct kvm_vcpu *vcpu);
+int handle_host_page_fault(struct kvm_vcpu *vcpu, unsigned long gpa);
 #endif /* __RISCV_KVM_HOST_H__ */
diff --git a/arch/riscv/kvm/kvm_riscv.c b/arch/riscv/kvm/kvm_riscv.c
index 07bf1ad..f95cea2 100644
--- a/arch/riscv/kvm/kvm_riscv.c
+++ b/arch/riscv/kvm/kvm_riscv.c
@@ -232,46 +232,66 @@ extern asmlinkage void enter_virtual_machine(void *);
 
 int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu, struct kvm_run *run)
 {
-	int ret;
+	int ret = 0;
+	unsigned long sie;
+	unsigned long hcause, gpa;
 
 	for (;;) {
 		/*
-		 * setup sstatus, prepare going into vm.
-		 * leave sstatus.spie as before.
+		 * Prepare for entering VM.
+		 *
+		 * 1.disable interrupt from now.
+		 *  Interrupt will be disabled until hret(VM Entry).
+		 *  Global SIE for Host OS is ignored,
+		 *  and interrupt for Host OS is enabled when VM running.
+		 * 2.setup VM privelege on hstatus.SR_PS.
 		 */
+		sie = csr_read_clear(sstatus, SR_IE);
 		if (vcpu->arch.prv) {
-			csr_set(sstatus, SR_PS);
+			csr_set(hstatus, SR_PS);
 		} else {
-			csr_clear(sstatus, SR_PS);
+			csr_clear(hstatus, SR_PS);
 		}
 
 		enter_virtual_machine(&vcpu->arch);
 
-		vcpu->arch.prv = csr_read(sstatus) & SR_PS;
+		vcpu->arch.prv = csr_read(hstatus) & SR_PS;
+		vcpu->arch.pc = csr_read(bpc);
+		hcause = csr_read_clear(hcause, ~0L);
+		gpa = csr_read(hvtval);
+
+		//Enable interrupt in hypervisor.
+		if (sie) {
+			csr_set(sstatus, SR_IE);
+		}
 
-		ret = handle_vm_exit(vcpu);
+		ret = handle_vm_exit(vcpu, hcause, gpa);
 		if (ret < 0) {
-			return ret;
+			break;
 		}
 	}
-	return 0;
+	return ret;
 }
 
-int handle_vm_exit(struct kvm_vcpu *vcpu)
+int handle_vm_exit(struct kvm_vcpu *vcpu, unsigned long cause, unsigned long gpa)
 {
-	unsigned long scause;
 	int ret;
 
-	scause = csr_read_clear(scause, ~0L);
-	switch (scause) {
+	switch (cause) {
 		case EXC_H_ECALL:
 			ret = handle_h_ecall(vcpu);
 			break;
 		case EXC_HOST_PAGE_FAULT:
-			ret = handle_host_page_fault(vcpu);
+			ret = handle_host_page_fault(vcpu, gpa);
+			break;
+		case 0:
+			/*
+			 * VM exit because of un delegated interrupt, no need to handle
+			 */
+			ret = 1;
 			break;
 		default:
-			printk("%s: unspported vm exit %lx\n", __func__, scause);
+			printk("%s: unspported vm exit %lx\n", __func__, cause);
 			return -ENOIOCTLCMD;
 	}
 
@@ -293,6 +313,9 @@ int handle_h_ecall(struct kvm_vcpu *vcpu)
 			retval = sbi_console_getchar();
 			break;
 		case SBI_SHUTDOWN:
+			pr_info("vm halted, vcpu id %d, user pid %d\n",
+					vcpu->vcpu_id, vcpu->kvm->userspace_pid);
+			return -1;
 		case SBI_SET_TIMER:
 		case SBI_SEND_IPI:
 		case SBI_REMOTE_SFENCE_VMA:
@@ -300,12 +323,11 @@ int handle_h_ecall(struct kvm_vcpu *vcpu)
 		case SBI_REMOTE_FENCE_I:
 		case SBI_CLEAR_IPI:
 		default:
-			printk("%s: unspported sbi %x, arg0 %lx, arg1 %lx\n",
+			printk("%s: unspported sbi %lx, arg0 %lx, arg1 %lx\n",
 					__func__, h_ecall_type, arg0, arg1);
 			return -ENOIOCTLCMD;
 	}
 	vcpu->arch.gpr[10] = retval;
-	vcpu->arch.pc = csr_read(bpc);
 	/* skip the current ecall instruction. */
 	vcpu->arch.pc += 4;
 	csr_write(bpc, vcpu->arch.pc);
@@ -344,7 +366,7 @@ static int build_tdp_page_table(struct kvm_vcpu *vcpu, gfn_t gfn, kvm_pfn_t pfn)
 			}
 			*((unsigned long *)pte_addr) = pte;
 		} else {
-			tmp_addr = pfn_to_virt(pte >> _PAGE_PFN_SHIFT);
+			tmp_addr = (unsigned long)pfn_to_virt(pte >> _PAGE_PFN_SHIFT);
 		}
 		base = tmp_addr;
 	}
@@ -352,10 +374,9 @@ static int build_tdp_page_table(struct kvm_vcpu *vcpu, gfn_t gfn, kvm_pfn_t pfn)
 	return 0;
 }
 
-int handle_host_page_fault(struct kvm_vcpu *vcpu)
+int handle_host_page_fault(struct kvm_vcpu *vcpu, unsigned long gpa)
 {
 	struct kvm_memory_slot *slot;
-	unsigned long gpa = csr_read(hvtval);
 	gfn_t gfn;
 	kvm_pfn_t pfn;
 	bool async, writable;
-- 
2.7.4

